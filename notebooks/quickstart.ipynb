{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a forge and execute an evolution cycle\n",
    "In this notebook, we will go through the very few steps needed to run a forge cycle for a given budget. \n",
    "Before running this notebook, you must set up a few things:\n",
    "\n",
    "**Your access to LLM's providers:**\n",
    "\n",
    "To try Ebiose, you must have access to at least one LLM provider. To provide the credentials, copy-paste the [`model_endpoints_template.yml`](./../model_endpoints_template.yml) file, rename it as `model_endpoints.yml` and fill it with your own credentials.\n",
    "\n",
    "**Add the root directory to your Python path**\n",
    "\n",
    "Depending on your settings, you may need to add the root of the repository to your `PYTHONPATH` environment variable. You may also use a `.env` file to do so. copy-paste the [`.env.template`](./../.env.template) file, rename it as `.env` and fill it with your own root directory.\n",
    "\n",
    "**Use LangFuse for tracing**\n",
    "\n",
    "Ebiose has chosen LangFuse to provide easy and free observability, through its self-hosted capability. Refer to [Langfuse official documentation](https://langfuse.com/self-hosting) to set it up. Once done, fill `LANGFUSE_SECRET_KEY`, `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_HOST` in the `.env` file.\n",
    "\n",
    "Other observability tools might be used but are not configured yet.\n",
    "\n",
    "**Load .env file**\n",
    "\n",
    "To load the `.env` file, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import litellm\n",
    "# litellm.success_callback = [\"langfuse\"]\n",
    "# litellm.failure_callback = [\"langfuse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a basic forge\n",
    "\n",
    "In ebiose, a **forge** is where custom agents are created to solve specific problems. The forge is the exclusive origin of new agents. Within each forge, architects agents orchestrate the creation and improvement of agents by reusing existing building blocks from the ecosystem.\n",
    "\n",
    "To create a forge and run a cycle, you must provide the following:\n",
    "- a description of the forge, which defines the problem that must be solved by generated agents;\n",
    "- the expected format of the agent's input and output, defined as Pydantic models;\n",
    "- an implementation of the `compute_fitness` abstract method that will be used by the forge to evaluate the generated agents.\n",
    "\n",
    "Let's say we wich to generate agents specialized in solving math problems. The forge description could be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge_description = \"Solving math word problems\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the expected input and output formats of the generated agents. These formats are to be defined as Pydantic models. \n",
    "\n",
    "For instance, in our context of solving math problems, we want the agent input to be a string which will represent the math problem to be solved and the agent output to be composed of two fields:\n",
    "- `solution` which will be the final solution to the math problem, given as an integer;\n",
    "- `rationale` which will be the rationale behind the found solution.\n",
    "\n",
    "The IO Pydantic models will thus be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class AgentInput(BaseModel):\n",
    "        math_problem: str\n",
    "\n",
    "class AgentOutput(BaseModel):\n",
    "    solution: int\n",
    "    rationale: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we must provide a way of evaluating the generated agents through the implementation of the `compute_fitness` abstract method of `AgentForge` class. For the sake of demonstration, we will here return a random float between 0 and 1, so that we don't spend tokens at evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xabier/dev/ebiose/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(11)\n",
    "\n",
    "from ebiose.core.agent import Agent\n",
    "from ebiose.core.agent_forge import AgentForge\n",
    "\n",
    "class BasicForge(AgentForge):\n",
    "    async def compute_fitness(self, agent: Agent, compute_token_id: str, **kwargs: dict[str, any]) -> float:\n",
    "        return random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantiate the forge with the provided elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge = BasicForge(\n",
    "    name=\"Basic forge\",\n",
    "    description=forge_description,\n",
    "    agent_input_model=AgentInput,\n",
    "    agent_output_model=AgentOutput,\n",
    "    default_generated_agent_engine_type=\"langgraph_engine\",\n",
    "    default_model_endpoint_id=None, # set to different model endpoint id if \n",
    "    # you want to use a specific model for generated agents, other than the default one defined in the model endpoint YAML file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a forge cycle\n",
    "\n",
    "Once the forge is instantiated, we can start generating agents by running a **forge cycle**. \n",
    "\n",
    "To do so, you must define:\n",
    "- a budget in dollars (the forge cycle will end once this budget is exhausted);\n",
    "- optionally, a path in which created agents and fitness will be saved accross generations. \n",
    "\n",
    "> ⚠️ Note that we need to use `asyncio.run` to launch the forge cycle.\n",
    "\n",
    "> 🚨 Before executing the following cell, check the amount of budget you have allocated!\n",
    "\n",
    "> 💡 If you are using VSCode, install the [*Markdown Preview Mermaid Support* extension](https://marketplace.visualstudio.com/items?itemName=bierner.markdown-mermaid) to allow the display of the generated agent's graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mStarting a new cycle for forge Basic forge\u001b[0m\n",
      "\u001b[1m****** Initializing agents population ******\u001b[0m\n",
      "\u001b[1mCreating 2 new agents with architect agents...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[34m\u001b[1m\n",
      "Initializing structured output agent for model AgentOutput (1)\u001b[0m\n",
      "100%|██████████| 2/2 [03:24<00:00, 102.33s/it]\n",
      "\u001b[34m\u001b[1mAgent initialization cost: 0.10513398500000001\u001b[0m\n",
      "\u001b[1mPopulation initialized with 2 agents\u001b[0m\n",
      "\u001b[1mInitialization of 2 agents took 0:03:24.678765\u001b[0m\n",
      "\u001b[1mBudget left after initialization: 0.39486601499999996 $\u001b[0m\n",
      "\u001b[1m****** Running generation 0 ******\u001b[0m\n",
      "\u001b[1mEvaluating current population of 2 agents...\u001b[0m\n",
      "100%|██████████| 2/2 [00:00<00:00, 7958.83it/s]\n",
      "\u001b[34m\u001b[1mAgent agent-6336dd07-b024-4145-a82c-f0c2ab5e2427 fitness: 0.9580423833198135, cost: 0.0\u001b[0m\n",
      "\u001b[34m\u001b[1mAgent agent-58963a8f-acb6-42c4-9e95-1d7a01ec8f89 fitness: 0.8473097733028044, cost: 0.0\u001b[0m\n",
      "\u001b[1mEvaluation took 0:00:00.001698 for a total cost of 0.0 $\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Agent ID: agent-6336dd07-b024-4145-a82c-f0c2ab5e2427\n",
       "## Fitness: 0.9580423833198135\n",
       "```mermaid \n",
       "graph LR\n",
       "\tStart_Node[start_node] --> Llm_1(ProblemInterpretor)\n",
       "\tLlm_1(ProblemInterpretor) --> Llm_2(ReasoningModule)\n",
       "\tLlm_2(ReasoningModule) --> Llm_3(VerificationModule)\n",
       "\tLlm_3(VerificationModule) -->|correct| Llm_4(ExplanationSynthesizer)\n",
       "\tLlm_3(VerificationModule) -->|error| Llm_2(ReasoningModule)\n",
       "\tLlm_4(ExplanationSynthesizer) --> End_Node[end_node]\n",
       " \n",
       "``` \n",
       "## Prompts:\n",
       "##### Shared context prompt\n",
       "This is a multi-agent system for solving math word problems. The system includes nodes for problem interpretation, reasoning, verification, and explanation synthesis. Each LLM node builds on the output of the previous node to ensure accuracy and clarity. Follow the instructions specific to your role to contribute effectively to the overall solution.\n",
       "##### ProblemInterpretor\n",
       "You are the ProblemInterpretor. Given the math word problem, extract all relevant numerical values, units, and context details. Then translate these components into precise mathematical expressions. Present your findings as a clear list of equations and extracted keywords, ensuring there is no ambiguity in the representation.\n",
       "##### ReasoningModule\n",
       "You are the ReasoningModule. Using the equations from the previous node, perform a detailed, step-by-step chain-of-thought reasoning process to solve the problem. Provide clear intermediate calculations and describe each logical step thoroughly.\n",
       "##### VerificationModule\n",
       "You are the VerificationModule. Evaluate the reasoning and computations from the previous step to check for accuracy and logical consistency. If the solution is correct, output 'correct'; if any errors or inconsistencies are detected, output 'error'. Provide a brief explanation for your judgment.\n",
       "##### ExplanationSynthesizer\n",
       "You are the ExplanationSynthesizer. Based on the validated solution, synthesize the final answer and generate a comprehensive explanation of the complete problem-solving process. Your explanation should be clear, concise, and easily understandable, summarizing both the computation and the underlying reasoning.\n",
       "\n",
       "# Agent ID: agent-58963a8f-acb6-42c4-9e95-1d7a01ec8f89\n",
       "## Fitness: 0.8473097733028044\n",
       "```mermaid \n",
       "graph LR\n",
       "\tStart_Node[start_node] --> Llm1(ProblemComprehension)\n",
       "\tLlm1(ProblemComprehension) --> Llm2(DataExtraction)\n",
       "\tLlm2(DataExtraction) --> Llm3(FormalTranslation)\n",
       "\tLlm3(FormalTranslation) --> Llm4(ChainReasoning)\n",
       "\tLlm4(ChainReasoning) --> Llm5(PreliminarySolution)\n",
       "\tLlm5(PreliminarySolution) --> Llm6(SolutionVerification)\n",
       "\tLlm6(SolutionVerification) -->|if solution is correct| Llm8(AnswerFormulation)\n",
       "\tLlm6(SolutionVerification) -->|if errors detected| Llm7(SelfReflection)\n",
       "\tLlm7(SelfReflection) --> Llm5(PreliminarySolution)\n",
       "\tLlm8(AnswerFormulation) --> End_Node[end_node]\n",
       " \n",
       "``` \n",
       "## Prompts:\n",
       "##### Shared context prompt\n",
       "You are a component within a collaborative AI system designed to solve complex math word problems. This system uses a chain-of-thought methodology, where each node in the graph performs a specialized task and passes clear, well-reasoned information to the next stage. Your responses should include all necessary details for downstream nodes, adhere to rigorous computational thinking, and contribute to a cohesive and iterative problem-solving process.\n",
       "##### ProblemComprehension\n",
       "You are tasked with reading the provided math word problem in detail. Identify and list all key numerical values, variables, units, and contextual elements present. Summarize in clear language what the problem is asking. Your analysis should establish a solid foundation for the upcoming steps by outlining the intent and critical components of the problem.\n",
       "##### DataExtraction\n",
       "From the problem description analyzed earlier, extract all essential numerical data and relevant variables. Present this data in a clear, organized list along with brief annotations explaining each item's significance. Your output should provide a comprehensive data set for building a formal mathematical representation.\n",
       "##### FormalTranslation\n",
       "Transform the extracted data and contextual information into a formal mathematical representation. This may involve setting up equations, inequalities, or expressions that accurately model the problem. Clearly outline the relationships between variables and state any assumptions that are needed for the mathematical model.\n",
       "##### ChainReasoning\n",
       "Based on the formal representation, articulate a detailed, step-by-step chain-of-thought that outlines possible solution approaches. Explain each reasoning step, including the mathematical operations and logical inferences you are using to move from the formal model to a potential solution. Your response should create a clear and logical pathway toward solving the problem.\n",
       "##### PreliminarySolution\n",
       "Using the chain-of-thought reasoning, propose an initial solution for the math word problem. Provide a detailed sequence of calculations or logical deductions that lead toward a potential answer. Ensure that your approach is well-structured and that every step is clearly justified to facilitate further verification.\n",
       "##### SolutionVerification\n",
       "Critically review the preliminary solution provided. Examine each step for mathematical consistency and logical soundness. If the solution appears correct, explicitly state that and explain why. If you find errors or inconsistencies, clearly describe the problems and suggest what needs to be revised. Your feedback will determine the next step in the process.\n",
       "##### SelfReflection\n",
       "Reflect on the feedback from the solution verification stage. Analyze any identified errors or weaknesses in the preliminary solution. Critically review your initial approach and propose concrete revisions or alternative strategies to address the issues found. Your insights should pave the way for a more robust solution.\n",
       "##### AnswerFormulation\n",
       "Using the refined solution and verification feedback, synthesize your work into a clear final answer. State the final result explicitly and provide a concise, comprehensive explanation of the key reasoning steps that led to this solution. Your final output should be mathematically rigorous and easy to understand.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mSaving current state to ../data/2025-04-08_14-05-55/generation=0\u001b[0m\n",
      "\u001b[1mStarting crossover and mutation...\u001b[0m\n",
      "\u001b[34m\u001b[1mError when calling azure/o3-mini: Error code: 400 - {'error': {'message': \"litellm.BadRequestError: litellm.ContentPolicyViolationError: litellm.ContentPolicyViolationError: AzureException - The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\\nmodel=azure/o3-mini. content_policy_fallback=None. fallbacks=None.\\n\\nSet 'content_policy_fallback' - https://docs.litellm.ai/docs/routing#fallbacks. Received Model Group=azure/o3-mini\\nAvailable Model Group Fallbacks=None\", 'type': None, 'param': None, 'code': '400'}}\u001b[0m\n",
      "\u001b[34m\u001b[1m\n",
      "Initializing structured output agent for model AgentOutput (2)\u001b[0m\n",
      "\u001b[34m\u001b[1mError while running agent agent-1876d184-6fea-4475-83ea-015d315b1e6d: list index out of range\u001b[0m\n",
      "\u001b[34m\u001b[1mCrossover agent failed creating a valid agent: 'NoneType' object has no attribute 'description'\u001b[0m\n",
      "\u001b[34m\u001b[1mError while generating offspring from ['agent-6336dd07-b024-4145-a82c-f0c2ab5e2427', 'agent-6336dd07-b024-4145-a82c-f0c2ab5e2427']. Falling back to architect agent.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     14\u001b[39m     SAVE_PATH.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m cycle_config = EvoForgingCycleConfig(\n\u001b[32m     18\u001b[39m     budget=\u001b[32m0.5\u001b[39m, \u001b[38;5;66;03m# the budget for the forge cycle in dollas\u001b[39;00m\n\u001b[32m     19\u001b[39m     n_agents_in_population=\u001b[32m2\u001b[39m, \u001b[38;5;66;03m# number of agents in the population, at each generation\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     save_path=SAVE_PATH, \u001b[38;5;66;03m# the path where results will be saved (optional)\u001b[39;00m\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m best_agents, best_fitness = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforge\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_new_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcycle_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ebiose/.venv/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ebiose/.venv/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ebiose/.venv/lib/python3.12/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/selectors.py:566\u001b[39m, in \u001b[36mKqueueSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    564\u001b[39m ready = []\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     kev_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "from ebiose.core.evo_forging_cycle import EvoForgingCycleConfig\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import UTC, datetime\n",
    "\n",
    "# the path where results will be saved\n",
    "current_time = datetime.now(UTC).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "SAVE_PATH = Path(f\"./../data/\") / current_time\n",
    "if not SAVE_PATH.exists():\n",
    "    SAVE_PATH.mkdir(parents=True)\n",
    "\n",
    "\n",
    "cycle_config = EvoForgingCycleConfig(\n",
    "    budget=1.0, # the budget for the forge cycle in dollas\n",
    "    n_agents_in_population=4, # number of agents in the population, at each generation\n",
    "    n_selected_agents_from_ecosystem=0, # number of agents selected from the ecosystem at initialization\n",
    "    n_best_agents_to_return=2, # number of best agents to return at the end of the cycle\n",
    "    replacement_ratio=0.5, # ratio of agents replaced at each generation\n",
    "    save_path=SAVE_PATH, # the path where results will be saved (optional)\n",
    "    node_types = [\"StartNode\", \"EndNode\", \"LLMNode\"],\n",
    ")\n",
    "\n",
    "best_agents, best_fitness = asyncio.run(\n",
    "    forge.run_new_cycle(config=cycle_config)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display the best agents that have been returned as follows. Note that:\n",
    "- all agents can be found in the `SAVE_PATH` directory if you defined one;\n",
    "- here, the compute fitness only returns a random float, so the following displayed agents have not been truly evaluated. \n",
    "\n",
    "Go check [examples/math_forge/math_forge.py](./../examples/math_forge/math_forge.py) to see a fully implemeted forge with a non-random fitness evaluation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display best agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Agent ID: agent-2951e239-9fc5-4609-beba-27e50c1d2e3a\n",
       "## Fitness: 0.2765476293735186\n",
       "```mermaid \n",
       "graph LR\n",
       "\tStart_Node[StartNode] --> Llm1(Problem Understanding)\n",
       "\tLlm1(Problem Understanding) --> Llm2(Problem Analysis)\n",
       "\tLlm2(Problem Analysis) --> Llm3(Solution Generation)\n",
       "\tLlm3(Solution Generation) --> End_Node[EndNode]\n",
       " \n",
       "``` \n",
       "## Prompts:\n",
       "##### Shared context prompt\n",
       "You are part of a collaborative network of Large Language Models (LLMs) designed to solve math word problems through a structured reasoning process. Each node in the network has a specific role:\n",
       "\n",
       "1. The Problem Understanding node extracts the key information from the given word problem.\n",
       "2. The Problem Analysis node evaluates the extracted information to determine the necessary mathematical operations.\n",
       "3. The Solution Generation node computes the final answer based on the analysis.\n",
       "\n",
       "Your task is to communicate effectively with the other models in the network, ensuring that your output is clear and informative, as it will guide the next node in the process. Emphasize chain-of-thought reasoning, self-reflection, and evaluative feedback where applicable.\n",
       "##### Problem Understanding\n",
       "You are tasked with understanding a math word problem and extracting its key information. Read the provided problem carefully. Identify and list the essential components, including the quantities involved, the relationships between them, and the question that needs to be answered.\n",
       "\n",
       "Additionally, reflect on the context of the problem and consider if there are any assumptions or clarifications needed. Your output should be a structured summary that clearly delineates the critical elements of the problem, as this will inform the next node in the process.\n",
       "\n",
       "For example, if the problem states, \"John has 5 apples and gives 2 to Mary. How many does he have left?\", your output should include:\n",
       "- Initial quantity of apples: 5\n",
       "- Quantity given away: 2\n",
       "- Final question: How many apples are left?\n",
       "##### Problem Analysis\n",
       "Your role is to analyze the key information provided by the Problem Understanding node. Based on the structured summary you received, evaluate the relationships between the quantities and determine the mathematical operations needed to solve the problem.\n",
       "\n",
       "Consider the following:\n",
       "1. What arithmetic operations (addition, subtraction, multiplication, division) are necessary?\n",
       "2. Are there multiple steps required to arrive at the solution?\n",
       "3. Are there any potential pitfalls or common errors that should be noted?\n",
       "\n",
       "Your output should be a clear, logical outline of the steps and operations required to solve the problem, which will guide the next node in generating the solution. Reflect on your analysis to ensure it is thorough and accurate.\n",
       "##### Solution Generation\n",
       "Your task is to generate the final solution to the math word problem based on the analysis provided by the Problem Analysis node. Start by reviewing the steps and operations outlined in the previous node.\n",
       "\n",
       "Follow these guidelines:\n",
       "1. Execute the necessary calculations step by step, clearly showing your reasoning.\n",
       "2. Provide the final answer to the question posed in the word problem.\n",
       "3. Include a brief reflection on the solution process, highlighting any assumptions made or potential errors to watch out for in similar problems.\n",
       "\n",
       "Your output should be the computed answer and a concise explanation of how you arrived at it, ensuring that the final result is clear and informative for the EndNode.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forge.display_results(best_agents, best_fitness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
