{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to test the Azure OpenAI model endpoint\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from ebiose.core.model_endpoint import ModelEndpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_endpoint = ModelEndpoints.get_model_endpoint(\"azure-gpt-4o-mini\") # This retrieves the model endpoint from ModelEndpoints\n",
    "model_endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM (Language Model) from Azure\n",
    "# Here we are initializing the LLM with the relevant parameters\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=model_endpoint.deployment_name,\n",
    "    azure_endpoint=model_endpoint.endpoint_url.get_secret_value(),\n",
    "    openai_api_key=model_endpoint.api_key.get_secret_value(),\n",
    "    openai_api_version=model_endpoint.api_version,\n",
    "    max_tokens=512,\n",
    "    temperature=0.3,\n",
    "    request_timeout=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"If Sarah has 3 apples and buys 4 more, then gives 2 to her friend, \"\n",
    "    \"how many apples does she have left?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e718fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the model and get a response\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "# Output the response content\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the result in a readable format\n",
    "print(\"\\n=== Model Response ===\\n\")\n",
    "print(response.content)\n",
    "print(\"\\n======================\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
