# model_endpoints_template.yml
# Rename this file to model_endpoints.yml 
# and fill in the API keys and endpoint URLs for the models you want to use

default_endpoint_id: "azure/gpt-4o-mini" 
default_architect_endpoint_id: "azure/gpt-4o"

lite_llm:
  use: true
  use_proxy: true
  api_key: "your-lite-llm-api-key" # fill in your Lite LLM API key
  api_base: "https://ebiose-litellm-proxy.greencliff-4ddafd29.francecentral.azurecontainerapps.io/"

endpoints:

  # OpenAI endpoints
  - endpoint_id: "gpt-4o-mini"
    provider: "OpenAI"
    api_key: "YOUR_OPENAI_API_KEY" # fill in your OpenAI API key

  # Azure OpenAI endpoints with LiteLLM proxy
  - endpoint_id: "azure/gpt-4o-mini"
    provider: "Azure OpenAI"
    
  - endpoint_id: "azure/gpt-4o"
    provider: "Azure OpenAI"

  - endpoint_id: "azure/o3-mini"
    provider: "Azure OpenAI"
  
  # Azure ML endpoints
  - endpoint_id: "llama3-8b"
    provider: "Azure ML"
    api_key: "YOUR_AZURE_ML_API_KEY" # fill in your Azure ML API key
    endpoint_url: "AZURE_ENDPOINT_URL" # fill in the Azure ML endpoint URL

  # Anthropic endpoints
  - endpoint_id: "claude-3-sonnet-20240229"
    provider: "Anthropic"
    api_key: "YOUR_OPENAI_API_KEY" # fill in your Anthropic API key

  # Hugging Face endpoints
  - endpoint_id: "microsoft/Phi-3-mini-4k-instruct"
    provider: "Hugging Face"